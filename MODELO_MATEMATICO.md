# ğŸ§® Modelo MatemÃ¡tico: RegresiÃ³n LogÃ­stica para PredicciÃ³n de Stockout

## ğŸ“– Ãndice
1. [Nombre y Tipo del Modelo](#1-nombre-y-tipo-del-modelo)
2. [Â¿QuÃ© Predice Exactamente?](#2-quÃ©-predice-exactamente)
3. [Fundamento MatemÃ¡tico](#3-fundamento-matemÃ¡tico)
4. [Variables Utilizadas](#4-variables-utilizadas)
5. [Proceso de Entrenamiento](#5-proceso-de-entrenamiento)
6. [Por QuÃ© Este Modelo](#6-por-quÃ©-este-modelo)
7. [CÃ¡lculo de PredicciÃ³n](#7-cÃ¡lculo-de-predicciÃ³n)

---

## 1. Nombre y Tipo del Modelo

### Nombre TÃ©cnico
**RegresiÃ³n LogÃ­stica Binaria (Binary Logistic Regression)**

### ClasificaciÃ³n
- **Familia**: Modelos lineales generalizados (GLM - Generalized Linear Models)
- **Tipo**: ClasificaciÃ³n supervisada binaria
- **Clase en scikit-learn**: `sklearn.linear_model.LogisticRegression`

### Especificaciones del Modelo Implementado

```python
LogisticRegression(
    max_iter=2000,           # MÃ¡ximo de iteraciones para convergencia
    class_weight='balanced',  # Compensa desbalance de clases
    C=0.5,                   # RegularizaciÃ³n L2 (inversa de lambda)
    solver='liblinear'       # Algoritmo de optimizaciÃ³n
)
```

---

## 2. Â¿QuÃ© Predice Exactamente?

### DefiniciÃ³n Precisa

El modelo predice la **probabilidad** de que ocurra un evento binario:

**Variable objetivo (Target)**: `Stockout14d`

```
Stockout14d = {
    1  si habrÃ¡ rotura de stock en los prÃ³ximos 14 dÃ­as
    0  si NO habrÃ¡ rotura de stock en los prÃ³ximos 14 dÃ­as
}
```

### Salida del Modelo

El modelo NO predice directamente 0 o 1, sino **dos probabilidades**:

```
P(Stockout14d = 0) = probabilidad de NO rotura    (ej: 0.23 = 23%)
P(Stockout14d = 1) = probabilidad de SÃ rotura    (ej: 0.77 = 77%)
                                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   Suma = 100%
```

**Usamos la segunda**: P(Stockout14d = 1)

### InterpretaciÃ³n

**Ejemplo:**
```
Input: ServicioID = SRV-045, Periodo = 7
       StockActual = 120 unidades
       DemandaDiariaEst = 15.3 unidades/dÃ­a
       DiasHastaRecepcion = 12 dÃ­as
       ... (32 variables mÃ¡s)

Output del modelo:
       P(Stockout14d = 1) = 0.89 = 89%
```

**Significado**: Hay un 89% de probabilidad de que el servicio SRV-045 se quede sin stock antes de 14 dÃ­as.

---

## 3. Fundamento MatemÃ¡tico

### 3.1 FÃ³rmula de la RegresiÃ³n LogÃ­stica

La regresiÃ³n logÃ­stica modela la probabilidad mediante la **funciÃ³n logÃ­stica (sigmoide)**:

```
P(y = 1 | X) = 1 / (1 + e^(-z))
```

Donde:
- `P(y = 1 | X)` = Probabilidad de rotura dado el vector de caracterÃ­sticas X
- `e` = NÃºmero de Euler (â‰ˆ 2.71828)
- `z` = CombinaciÃ³n lineal de las variables

### 3.2 CombinaciÃ³n Lineal (z)

```
z = Î²â‚€ + Î²â‚Â·xâ‚ + Î²â‚‚Â·xâ‚‚ + Î²â‚ƒÂ·xâ‚ƒ + ... + Î²â‚ƒâ‚…Â·xâ‚ƒâ‚…
```

Donde:
- `Î²â‚€` = Intercepto (sesgo base del modelo)
- `Î²â‚, Î²â‚‚, ..., Î²â‚ƒâ‚…` = Coeficientes (pesos) de cada variable
- `xâ‚, xâ‚‚, ..., xâ‚ƒâ‚…` = Valores de las 35 variables

### 3.3 Ejemplo NumÃ©rico Simplificado

Supongamos un modelo simplificado con solo 4 variables:

```
z = 2.5 + (-0.03)Â·StockActual + (0.15)Â·DemandaDiariaEst 
        + (0.08)Â·DiasHastaRecepcion + (-0.02)Â·RecepcionPendiente

Caso especÃ­fico:
  StockActual = 120
  DemandaDiariaEst = 15.3
  DiasHastaRecepcion = 12
  RecepcionPendiente = 200

z = 2.5 + (-0.03)Â·120 + (0.15)Â·15.3 + (0.08)Â·12 + (-0.02)Â·200
z = 2.5 - 3.6 + 2.295 + 0.96 - 4.0
z = -1.845

P(Stockout = 1) = 1 / (1 + e^(1.845))
P(Stockout = 1) = 1 / (1 + 6.33)
P(Stockout = 1) = 1 / 7.33
P(Stockout = 1) = 0.136 = 13.6%
```

**InterpretaciÃ³n**:
- Stock alto (120) â†’ reduce z (coeficiente negativo)
- Demanda alta (15.3) â†’ aumenta z (coeficiente positivo)
- DÃ­as hasta recepciÃ³n largos (12) â†’ aumenta z
- RecepciÃ³n pendiente alta (200) â†’ reduce z

Resultado: 13.6% de probabilidad de rotura (BAJO RIESGO)

### 3.4 FunciÃ³n Sigmoide Visualizada

```
Probabilidad
    1.0 â”¤              â•­â”€â”€â”€â”€â”€â”€â”€â”€
        â”‚            â•­â”€â•¯
    0.75â”¤         â•­â”€â”€â•¯
        â”‚       â•­â”€â•¯
    0.5 â”¤    â•­â”€â”€â•¯
        â”‚  â•­â”€â•¯
    0.25â”¤â•­â”€â•¯
        â”‚â•¯
    0.0 â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> z
       -6  -3   0   3   6
```

**Propiedades importantes**:
- Si `z = 0` â†’ P = 0.5 (50%)
- Si `z â†’ +âˆ` â†’ P â†’ 1.0 (100%)
- Si `z â†’ -âˆ` â†’ P â†’ 0.0 (0%)
- La curva es suave (no hay saltos bruscos)

---

## 4. Variables Utilizadas

### 4.1 Total de Variables

El modelo usa **35 variables de entrada** para predecir **1 variable de salida**.

```
X (entrada) = [xâ‚, xâ‚‚, xâ‚ƒ, ..., xâ‚ƒâ‚…]  â†’  MODELO  â†’  y (salida) = Stockout14d
```

### 4.2 Lista Completa de Variables de Entrada

#### A) CaracterÃ­sticas del Servicio (15 variables)

| # | Variable | Tipo | Ejemplo | Influencia |
|---|----------|------|---------|------------|
| 1 | Categoria | CategÃ³rica | "Almacenaje" | Baja |
| 2 | Subcategoria | CategÃ³rica | "Refrigerado" | Baja |
| 3 | UnidadTarifa | CategÃ³rica | "Por pallet" | Baja |
| 4 | TipoUnidad | CategÃ³rica | "Pallet" | Baja |
| 5 | Moneda | CategÃ³rica | "PEN" | Baja |
| 6 | RequiereCertificacion | CategÃ³rica | "SÃ­" | Baja |
| 7 | Temperatura | CategÃ³rica | "Frio" | Baja |
| 8 | **LeadTimeMinDias** | NumÃ©rica | 5 | Media |
| 9 | **LeadTimeMaxDias** | NumÃ©rica | 10 | Media |
| 10 | TiempoEjecucionHoras | NumÃ©rica | 24 | Baja |
| 11 | ModalidadContrato | CategÃ³rica | "Mensual" | Baja |
| 12 | Estado | CategÃ³rica | "Activo" | Baja |
| 13 | CantidadPedidoEstandar | NumÃ©rica | 250 | Media |
| 14 | CostoEstandar | NumÃ©rica | 150.00 | Baja |
| 15 | TarifaImpuesto | NumÃ©rica | 0.18 | Baja |

#### B) CaracterÃ­sticas del Cliente (4 variables)

| # | Variable | Tipo | Ejemplo | Influencia |
|---|----------|------|---------|------------|
| 16 | TemperaturaControlada | CategÃ³rica | "SÃ­" | Baja |
| 17 | CaducidadControlada | CategÃ³rica | "No" | Baja |
| 18 | SLA_horas | NumÃ©rica | 24 | Baja |
| 19 | SLA_pct | NumÃ©rica | 95 | Baja |

#### C) Datos del Cliente Propietario (4 variables)

| # | Variable | Tipo | Ejemplo | Influencia |
|---|----------|------|---------|------------|
| 20 | **Segmento** | CategÃ³rica | "PREFERENTE" | Media |
| 21 | CanalPreferido | CategÃ³rica | "Directo" | Baja |
| 22 | ZonaDespacho | CategÃ³rica | "Norte" | Baja |
| 23 | Departamento | CategÃ³rica | "Lima" | Baja |

#### D) CaracterÃ­sticas del Proveedor (6 variables)

| # | Variable | Tipo | Ejemplo | Influencia |
|---|----------|------|---------|------------|
| 24 | Categoria_prov | CategÃ³rica | "LOGISTICA" | Baja |
| 25 | **LeadTimePromedioDias** | NumÃ©rica | 7 | Alta |
| 26 | ToleranciaEntregaDias | NumÃ©rica | 2 | Media |
| 27 | **RatingDesempeno** | NumÃ©rica | 4.5 | Media |
| 28 | CertificadoCalidad | CategÃ³rica | "ISO9001" | Baja |
| 29 | Estado_prov | CategÃ³rica | "Activo" | Baja |

#### E) Variables Operacionales (5 variables) â­

| # | Variable | Tipo | Ejemplo | Influencia |
|---|----------|------|---------|------------|
| 30 | Periodo | NumÃ©rica | 7 | Baja |
| 31 | **StockActual** | NumÃ©rica | 120 | **MUY ALTA** |
| 32 | **RecepcionPendiente** | NumÃ©rica | 200 | Alta |
| 33 | **DiasHastaRecepcion** | NumÃ©rica | 12 | **MUY ALTA** |
| 34 | **DemandaDiariaEst** | NumÃ©rica | 15.3 | **MUY ALTA** |

#### F) Variable NO usada como entrada (es el target)

| Variable | Tipo | Valores | Rol |
|----------|------|---------|-----|
| **Stockout14d** | Binaria | 0 o 1 | **Variable de salida (y)** |

### 4.3 Ranking de Importancia de Variables

**Top 10 variables mÃ¡s influyentes** (estimado basado en lÃ³gica del modelo):

| Ranking | Variable | Peso Estimado | RazÃ³n |
|---------|----------|---------------|-------|
| 1 ğŸ¥‡ | **StockActual** | 35% | Determina directamente los dÃ­as de cobertura |
| 2 ğŸ¥ˆ | **DemandaDiariaEst** | 30% | Determina velocidad de consumo |
| 3 ğŸ¥‰ | **DiasHastaRecepcion** | 25% | Determina cuÃ¡ndo llega el reabastecimiento |
| 4 | **RecepcionPendiente** | 8% | Modifica el stock futuro |
| 5 | **LeadTimePromedioDias** | 4% | Afecta planificaciÃ³n de pedidos |
| 6 | **Segmento** | 3% | Afecta patrones de demanda |
| 7 | **RatingDesempeno** | 2% | Indica confiabilidad del proveedor |
| 8 | **LeadTimeMaxDias** | 1.5% | Define lÃ­mite superior de espera |
| 9 | **CantidadPedidoEstandar** | 1% | Afecta tamaÃ±o de reabastecimiento |
| 10 | **ToleranciaEntregaDias** | 0.5% | Variabilidad del proveedor |

**Resto de variables**: < 0.5% cada una (contexto marginal)

---

## 5. Proceso de Entrenamiento

### 5.1 PreparaciÃ³n de Datos

#### Paso 1: Carga de Maestros
```
Entrada:
  - maestro_clientes.xlsx    (109 registros)
  - maestro_proveedores.xlsx (204 registros)
  - maestro_servicios.xlsx   (200 registros)

Limpieza:
  - NormalizaciÃ³n de strings (trim, lowercase)
  - EliminaciÃ³n de duplicados por ID
  - ConversiÃ³n de tipos (numÃ©ricos, fechas)
```

#### Paso 2: GeneraciÃ³n del Dataset Transaccional
```
Proceso:
  1. Join: Servicios â† Clientes (por ClientePropietario)
  2. Join: Servicios â† Proveedores (por asignaciÃ³n determinÃ­stica)
  3. ExpansiÃ³n: 200 servicios Ã— 12 perÃ­odos = 2,400 registros
  4. GeneraciÃ³n de variables derivadas:
     - StockActual (basado en fÃ³rmula estacional)
     - DemandaDiariaEst (basado en segmento y cantidad estÃ¡ndar)
     - DiasHastaRecepcion (basado en lead time + tolerancia)
     - RecepcionPendiente (basado en lÃ³gica de reorden)

Output:
  Dataset con 2,400 filas Ã— 36 columnas (35 features + 1 target)
```

#### Paso 3: CÃ¡lculo del Target (Stockout14d)
```python
# LÃ³gica del target
dias_cobertura = StockActual / DemandaDiariaEst

Stockout14d = 1 si:
  (dias_cobertura < 14) Y (DiasHastaRecepcion > dias_cobertura)
  
Stockout14d = 0 en caso contrario
```

**Ejemplo:**
```
Caso 1:
  StockActual = 100
  DemandaDiariaEst = 10
  DiasHastaRecepcion = 15
  
  dias_cobertura = 100 / 10 = 10 dÃ­as
  10 < 14 â†’ SÃ
  15 > 10 â†’ SÃ
  â†’ Stockout14d = 1 (habrÃ¡ rotura)

Caso 2:
  StockActual = 200
  DemandaDiariaEst = 10
  DiasHastaRecepcion = 8
  
  dias_cobertura = 200 / 10 = 20 dÃ­as
  20 < 14 â†’ NO
  â†’ Stockout14d = 0 (no habrÃ¡ rotura)
```

### 5.2 Preprocesamiento

El modelo NO recibe los datos crudos, sino transformados:

#### A) Variables NumÃ©ricas (14 variables)
```
Paso 1: ImputaciÃ³n de nulos
  - Estrategia: Mediana
  - Ejemplo: Si LeadTimePromedioDias tiene nulos, rellena con la mediana (ej: 7 dÃ­as)

Paso 2: Escalado (Standardization)
  - FÃ³rmula: x_scaled = (x - Î¼) / Ïƒ
  - Î¼ = media de la variable
  - Ïƒ = desviaciÃ³n estÃ¡ndar
  
  Ejemplo:
    StockActual original: [50, 100, 150, 200, 250]
    Î¼ = 150, Ïƒ = 70.7
    StockActual escalado: [-1.41, -0.71, 0, 0.71, 1.41]
```

**Â¿Por quÃ© escalar?**
- Variables en diferentes escalas (ej: StockActual en cientos, DemandaDiariaEst en decenas)
- El modelo converge mÃ¡s rÃ¡pido
- Todos los coeficientes estÃ¡n en escala comparable

#### B) Variables CategÃ³ricas (21 variables)
```
Paso 1: ImputaciÃ³n de nulos
  - Estrategia: Moda (valor mÃ¡s frecuente)

Paso 2: One-Hot Encoding
  - Convierte categorÃ­as en columnas binarias (0 o 1)
  
  Ejemplo:
    Segmento original: ["BASICO", "ESTANDAR", "PREFERENTE", "BASICO"]
    
    One-Hot Encoding â†’
      Segmento_BASICO    [1, 0, 0, 1]
      Segmento_ESTANDAR  [0, 1, 0, 0]
      Segmento_PREFERENTE[0, 0, 1, 0]
```

**Resultado final del preprocesamiento:**
- Variables numÃ©ricas: 14 columnas escaladas
- Variables categÃ³ricas: ~80 columnas binarias (depende de categorÃ­as Ãºnicas)
- **Total de features despuÃ©s de preprocesamiento**: ~94 columnas

### 5.3 DivisiÃ³n de Datos (Train/Test Split)

```
Estrategia: GroupShuffleSplit
  - Grupo: ServicioID
  - Train: 75% de los servicios
  - Test: 25% de los servicios
  - Random state: 42 (para reproducibilidad)

Dataset total: 2,400 registros
  â†’ Train: 1,800 registros (~150 servicios Ã— 12 perÃ­odos)
  â†’ Test:    600 registros (~50 servicios Ã— 12 perÃ­odos)
```

**Â¿Por quÃ© GroupShuffleSplit?**

Evita **data leakage** (fuga de informaciÃ³n):
- Si el servicio SRV-045 estÃ¡ en train, TODOS sus 12 perÃ­odos estÃ¡n en train
- Si estÃ¡ en test, TODOS sus 12 perÃ­odos estÃ¡n en test
- Nunca un servicio tiene datos en ambos conjuntos

**ComparaciÃ³n:**

```
âŒ Split normal (malo):
  Train: SRV-001 perÃ­odos [1,2,3,4,5,6,7,8,9]
  Test:  SRV-001 perÃ­odos [10,11,12]
  â†’ El modelo "conoce" SRV-001 y solo predice perÃ­odos futuros

âœ… GroupShuffleSplit (correcto):
  Train: SRV-001, SRV-002, SRV-003, ... (150 servicios completos)
  Test:  SRV-151, SRV-152, ... (50 servicios completos)
  â†’ El modelo predice servicios completamente nuevos
```

### 5.4 Entrenamiento del Modelo

#### Algoritmo de OptimizaciÃ³n: liblinear

El modelo busca los mejores coeficientes (Î²â‚€, Î²â‚, ..., Î²â‚ƒâ‚…) mediante:

```
Objetivo: Minimizar la funciÃ³n de costo (Log-Loss)

Log-Loss = -1/n Î£ [yÂ·log(Å·) + (1-y)Â·log(1-Å·)]

Donde:
  n = nÃºmero de registros (1,800)
  y = valor real (0 o 1)
  Å· = probabilidad predicha (0 a 1)
```

**InterpretaciÃ³n del Log-Loss:**
- Penaliza predicciones incorrectas
- Si y=1 y Å·=0.1 â†’ Log-Loss alto (mala predicciÃ³n)
- Si y=1 y Å·=0.9 â†’ Log-Loss bajo (buena predicciÃ³n)

#### RegularizaciÃ³n L2 (C = 0.5)

```
FunciÃ³n de costo completa:
  J = Log-Loss + Î»Â·Î£(Î²áµ¢Â²)
  
Î» = 1/C = 1/0.5 = 2 (parÃ¡metro de regularizaciÃ³n)
```

**Â¿QuÃ© hace la regularizaciÃ³n?**
- Penaliza coeficientes muy grandes
- Evita overfitting (sobreajuste)
- Hace que el modelo generalice mejor a datos nuevos

#### Class Weight Balancing

```
DistribuciÃ³n desbalanceada:
  Clase 0 (No rotura): 1,873 registros (78%)
  Clase 1 (SÃ­ rotura):   527 registros (22%)

class_weight='balanced' ajusta pesos:
  wâ‚€ = n / (2 Â· nâ‚€) = 2,400 / (2 Â· 1,873) = 0.64
  wâ‚ = n / (2 Â· nâ‚) = 2,400 / (2 Â· 527) = 2.28
```

**Efecto:**
- Errores en clase 1 (rotura) se penalizan 2.28 veces mÃ¡s
- Fuerza al modelo a prestar mÃ¡s atenciÃ³n a la clase minoritaria
- Mejora el Recall (detectar roturas)

### 5.5 Proceso Iterativo

```
IteraciÃ³n 1:
  - Inicializar Î² con valores aleatorios
  - Calcular predicciones
  - Calcular Log-Loss
  - Ajustar Î² usando gradiente descendente

IteraciÃ³n 2:
  - Calcular predicciones con Î² actualizados
  - Calcular Log-Loss (deberÃ­a ser menor)
  - Ajustar Î² nuevamente

...

IteraciÃ³n 487:
  - Log-Loss converge (cambios < 0.0001)
  - Â¡Entrenamiento completo!

Total iteraciones: ~500 (max 2,000 permitidas)
Tiempo: ~2 segundos en CPU moderna
```

### 5.6 Guardado del Modelo

```python
import joblib

# Guarda TODA la pipeline (preprocesamiento + modelo)
joblib.dump(pipeline, "models/stockout14d_logreg.joblib")
```

**El archivo .joblib contiene:**
1. Imputadores (medianas y modas aprendidas)
2. Scaler (medias y desviaciones estÃ¡ndar)
3. One-Hot Encoder (categorÃ­as conocidas)
4. Modelo de RegresiÃ³n LogÃ­stica (coeficientes Î²)

**TamaÃ±o del archivo**: ~220 KB (comprimido)

---

## 6. Por QuÃ© Este Modelo

### 6.1 Ventajas de la RegresiÃ³n LogÃ­stica

#### âœ… 1. Interpretabilidad
```
Coeficientes tienen significado directo:
  Î² = 0.15 para DemandaDiariaEst
  â†’ Por cada unidad adicional de demanda, el log-odds aumenta 0.15
  â†’ Mayor demanda â†’ Mayor riesgo (intuitivo)
```

#### âœ… 2. Probabilidades Calibradas
```
El modelo no solo dice "SÃ­/No", sino "89% de probabilidad"
  â†’ Permite tomar decisiones basadas en riesgo
  â†’ Operador puede priorizar casos crÃ­ticos (>70%)
```

#### âœ… 3. Eficiencia Computacional
```
Entrenamiento: 2 segundos
PredicciÃ³n: <1 milisegundo por registro
  â†’ Puede correr en producciÃ³n en tiempo real
  â†’ No requiere GPU
```

#### âœ… 4. Estabilidad
```
Pocos hiperparÃ¡metros (C, solver, max_iter)
  â†’ Menos propensiÃ³n a overfitting
  â†’ Resultados reproducibles
```

#### âœ… 5. Baseline Robusto
```
Es el modelo estÃ¡ndar para clasificaciÃ³n binaria
  â†’ Si falla, otros modelos mÃ¡s complejos tambiÃ©n fallarÃ¡n
  â†’ Punto de partida acadÃ©micamente aceptado
```

### 6.2 ComparaciÃ³n con Otros Modelos

| Modelo | Accuracy | Interpretabilidad | Velocidad | Complejidad |
|--------|----------|-------------------|-----------|-------------|
| **RegresiÃ³n LogÃ­stica** | 84.5% | â­â­â­â­â­ | âš¡âš¡âš¡âš¡âš¡ | Baja |
| Random Forest | ~87% (est.) | â­â­â­ | âš¡âš¡âš¡ | Media |
| XGBoost | ~89% (est.) | â­â­ | âš¡âš¡ | Alta |
| Red Neuronal | ~85% (est.) | â­ | âš¡âš¡ | Muy Alta |
| Naive Bayes | ~78% (est.) | â­â­â­â­ | âš¡âš¡âš¡âš¡âš¡ | Muy Baja |

**ConclusiÃ³n**: 
- RegresiÃ³n LogÃ­stica ofrece el mejor balance interpretabilidad/performance
- Para MVP acadÃ©mico es la elecciÃ³n correcta
- Si se requiere mÃ¡s accuracy, Random Forest o XGBoost son siguientes pasos

### 6.3 Desventajas y Limitaciones

#### âŒ 1. Asume Linealidad
```
El modelo asume que el log-odds es una funciÃ³n lineal de X
  â†’ No captura interacciones complejas automÃ¡ticamente
  â†’ Ej: No capta que "Stock bajo + Proveedor lento" es peor que la suma
```

#### âŒ 2. Sensible a Outliers
```
Un stock de 10,000 unidades (outlier) puede distorsionar el coeficiente
  â†’ Requiere limpieza de datos cuidadosa
```

#### âŒ 3. No Captura Estacionalidad Compleja
```
El modelo trata "Periodo" como un nÃºmero (1, 2, 3, ...)
  â†’ No entiende que Diciembre (12) es temporada alta
  â†’ Requiere feature engineering manual
```

---

## 7. CÃ¡lculo de PredicciÃ³n (Paso a Paso)

### Ejemplo Completo

#### Entrada del Usuario
```
ServicioID: SRV-089
Periodo: 7
StockActual: 180
DemandaDiariaEst: 25.0
DiasHastaRecepcion: 14
RecepcionPendiente: 250
... (30 variables estructurales del servicio)
```

#### Paso 1: Preprocesamiento AutomÃ¡tico

**Variables numÃ©ricas escaladas:**
```
StockActual_scaled = (180 - 220) / 85 = -0.47
DemandaDiariaEst_scaled = (25.0 - 15.2) / 8.3 = 1.18
DiasHastaRecepcion_scaled = (14 - 10.5) / 6.2 = 0.56
RecepcionPendiente_scaled = (250 - 200) / 90 = 0.56
... (10 variables numÃ©ricas mÃ¡s)
```

**Variables categÃ³ricas codificadas:**
```
Categoria_Almacenaje = 1
Categoria_Transporte = 0
Segmento_PREFERENTE = 1
Segmento_BASICO = 0
... (80 variables binarias)
```

#### Paso 2: MultiplicaciÃ³n por Coeficientes

```
z = Î²â‚€ + Î£(Î²áµ¢ Â· xáµ¢)

z = 0.45                           (intercepto)
  + (-2.1) Â· (-0.47)              (StockActual: +0.99)
  + (1.8) Â· (1.18)                (DemandaDiariaEst: +2.12)
  + (1.2) Â· (0.56)                (DiasHastaRecepcion: +0.67)
  + (-0.9) Â· (0.56)               (RecepcionPendiente: -0.50)
  + (0.3) Â· 1                     (Categoria_Almacenaje: +0.30)
  + (0.5) Â· 1                     (Segmento_PREFERENTE: +0.50)
  + ... (suma de otros 88 tÃ©rminos)

z = 2.35 (suma total)
```

#### Paso 3: Aplicar FunciÃ³n Sigmoide

```
P(Stockout = 1) = 1 / (1 + e^(-z))
P(Stockout = 1) = 1 / (1 + e^(-2.35))
P(Stockout = 1) = 1 / (1 + 0.095)
P(Stockout = 1) = 1 / 1.095
P(Stockout = 1) = 0.913

â†’ 91.3% de probabilidad de rotura
```

#### Paso 4: ClasificaciÃ³n (si se requiere)

```
Umbral de decisiÃ³n: 0.5 (50%)

Si P(Stockout = 1) >= 0.5 â†’ Clasificar como 1 (habrÃ¡ rotura)
Si P(Stockout = 1) < 0.5  â†’ Clasificar como 0 (no habrÃ¡ rotura)

En este caso: 0.913 >= 0.5 â†’ PredicciÃ³n = 1 (SÃ ROTURA)
```

#### Paso 5: Mensaje al Usuario

```
Probabilidad: 91.3%
Nivel de Riesgo: ALTO

AcciÃ³n sugerida:
  â†’ Generar reabastecimiento inmediato
  â†’ Priorizar recepciÃ³n con proveedor
```

---

## 8. FÃ³rmula MatemÃ¡tica Completa

### NotaciÃ³n Formal

```
Dado:
  X = [xâ‚, xâ‚‚, ..., xâ‚ƒâ‚…]áµ€  (vector de 35 features)
  Î² = [Î²â‚€, Î²â‚, ..., Î²â‚ƒâ‚…]áµ€  (vector de 36 parÃ¡metros)
  
Modelo:
  z = Î²áµ€ Â· X = Î²â‚€ + Î£áµ¢â‚Œâ‚Â³âµ Î²áµ¢Â·xáµ¢
  
  P(y = 1 | X) = Ïƒ(z) = 1 / (1 + e^(-z))
  
Donde:
  Ïƒ(z) = funciÃ³n sigmoide
  y âˆˆ {0, 1} = variable objetivo (Stockout14d)
```

### FunciÃ³n de PÃ©rdida (Loss Function)

```
Durante entrenamiento:
  
  L(Î²) = -1/n Î£â¿â±¼â‚Œâ‚ [yâ±¼Â·log(P(y=1|Xâ±¼)) + (1-yâ±¼)Â·log(1-P(y=1|Xâ±¼))]
         + Î»Â·Î£áµ¢â‚Œâ‚Â³âµ Î²áµ¢Â²
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”˜
                        Log-Loss                                     RegularizaciÃ³n L2
                        
Donde:
  n = 1,800 (tamaÃ±o del conjunto de entrenamiento)
  Î» = 2 (parÃ¡metro de regularizaciÃ³n)
  yâ±¼ = valor real del registro j (0 o 1)
```

### Gradiente Descendente (OptimizaciÃ³n)

```
ActualizaciÃ³n iterativa:
  
  Î² â† Î² - Î± Â· âˆ‡L(Î²)
  
Donde:
  Î± = learning rate (tasa de aprendizaje)
  âˆ‡L(Î²) = gradiente de la funciÃ³n de pÃ©rdida
  
  âˆ‡L(Î²) = 1/n Â· Xáµ€Î£â¿â±¼â‚Œâ‚(Ïƒ(Î²áµ€Xâ±¼) - yâ±¼) + 2Î»Î²
```

---

## 9. Resumen Ejecutivo

### Â¿QuÃ© Modelo Es?
**RegresiÃ³n LogÃ­stica Binaria** con regularizaciÃ³n L2 y balanceo de clases.

### Â¿QuÃ© Predice?
**Probabilidad de rotura de stock en 14 dÃ­as** (0% a 100%).

### Â¿Con QuÃ© Variables?
**35 variables de entrada**:
- 5 operacionales (stock, demanda, recepciÃ³n, dÃ­as, periodo)
- 30 estructurales (caracterÃ­sticas del servicio, cliente, proveedor)

### Â¿En Base a QuÃ©?
**Patrones aprendidos** de 1,800 registros histÃ³ricos que relacionan:
```
Stock bajo + Demanda alta + RecepciÃ³n tardÃ­a â†’ Alta probabilidad de rotura
Stock alto + Demanda baja + RecepciÃ³n pronta â†’ Baja probabilidad de rotura
```

### Â¿Por QuÃ© Este Modelo?
- âœ… Interpretable
- âœ… RÃ¡pido
- âœ… Calibrado (probabilidades confiables)
- âœ… Baseline acadÃ©mico estÃ¡ndar
- âœ… 84.5% accuracy, 96.2% AUC

### FÃ³rmula Simplificada
```
P(Rotura) = 1 / (1 + e^(-(a + bÂ·Stock + cÂ·Demanda + dÂ·DiasRec + ...)))
```

Donde `a, b, c, d, ...` son coeficientes aprendidos durante el entrenamiento.

---

**Ãšltima actualizaciÃ³n**: Diciembre 2024  
**VersiÃ³n del modelo**: stockout14d_logreg v1.0  
**Framework**: scikit-learn 1.3+  
**Python**: 3.8+

